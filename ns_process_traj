#!/usr/bin/env python

import optparse

p = optparse.OptionParser(usage='%prog [options] <infile> [ <infile> ... ]')
p.add_option('-n','--no-headers', action='store_true', help="""process a file with V and KE missing from headers""")
p.add_option('-t','--trajectory', action='store_true', help="""produce combined trajectory""")
p.add_option('-i','--interval', action='store', help="""interval to output trajectory""", type='int', default=1)
p.add_option('-f','--format', action='store', help="""input (and if stdout also output) file format""", type='string', default=None)
p.add_option('-o','--output', action='store', help="""output file name""", type='string', default='stdout')
p.add_option('-e','--energies_file', action='store', help="""energies file name for fixing restart-related inconsistencies""", type='string', default=None)

opt, args = p.parse_args()

import sys, re, subprocess
import numpy as np

if len(args) <= 0:
    sys.stderr.write("Need at least one trajectory file to process\n")
    sys.exit(2)

if opt.trajectory or opt.no_headers:
   import quippy

re_e =      re.compile('ns_energy=([^ ]*)')
re_volume = re.compile('volume=([^ ]*)')
re_iter = re.compile('iter=([^ ]*)')
re_KE =     re.compile('ns_KE=([^ ]*)')

def process_headers(file):
   proc = subprocess.Popen(['fgrep','Lattice',file],stdout=subprocess.PIPE)
   data = []
   for l in proc.stdout:

      r_e = re_e.search(l)
      if r_e is not None:
	 r_e = float(r_e.group(1))

      r_volume = re_volume.search(l)
      if r_volume is not None:
	 r_volume = float(r_volume.group(1))

      r_iter = re_iter.search(l)
      if r_iter is not None:
	 r_iter = int(r_iter.group(1))

      r_KE = re_KE.search(l)
      if r_KE is not None:
	 try:
	    r_KE = float(r_KE.group(1))
	 except:
	    r_KE = 0.0

      data.append([r_iter, r_e, r_volume, r_KE])
   return data

def traj_iter(files, interval=1, energies_file=None):
    # print "traj_iter files interval Ts ", files, interval, Ts
    n_files=len(files)
    n_done=0
    global_i = 0

    configs=[None]*n_files
    energies=np.zeros(n_files)
    atom_readers=[]
    # print "n_files ",n_files
    # print "files ", files
    for i in range(n_files):
        # print i
        # sys.stderr.write("starting file {}\n".format(files[i]))
        sys.stderr.write("%d" % (i % 10))
        ar = iter(quippy.AtomsReader(files[i], format=opt.format))
        atom_readers.append(ar)
        configs[i] = ar.next()
        energies[i] = configs[i].info['ns_energy']
    sys.stderr.write("\n")

    if energies_file is not None:
        sys.stderr.write("starting energies file\n")
        with open(energies_file,"r") as f:
            top_line = f.readline()
            all_energies = np.loadtxt(f)

    sys.stderr.write("starting iterator\n")
    while True:
        # print "n_done ",n_done, "n_files", n_files
        if n_done == n_files:
            raise StopIteration()

        # print "energies ", energies
        highest_E_i = energies.argmax()
        energy_match=True
        if opt.energies_file is not None:
            cur_iter = configs[highest_E_i].info['iter']
            E_ind_list = np.where(all_energies[:,0] == cur_iter)[0]
            ns_E = configs[highest_E_i].info['ns_energy']
            min_dE = np.min(np.abs(ns_E-all_energies[E_ind_list,1]))
            # print "check match",
            # print "cur iter", cur_iter, "E_ind_list",E_ind_list
            # print "ns_E",ns_E, "all_energies[E_ind_list]",all_energies[E_ind_list,1]
            # print "min_dE", min_dE, "ratio",min_dE/np.abs(ns_E)
            energy_match = (min_dE <= 1.0e-11 and np.abs(ns_E) < 1) or (min_dE/np.abs(ns_E) < 1.0e-11)
            # print "energy_match",energy_match

        if energy_match:
            # print "highest_E_i ",highest_E_i
            if global_i % interval == interval-1:
                if opt.trajectory:
                    configs[highest_E_i].info['ns_global_i'] = global_i
                    yield configs[highest_E_i]
                else:
                    if configs[highest_E_i].has('masses') and configs[highest_E_i].has('momenta'):
                        KE = configs[highest_E_i].get_kinetic_energy()
                    else:
                        KE = None
                    yield [configs[highest_E_i].info['iter'], configs[highest_E_i].info['ns_energy'], configs[highest_E_i].get_volume(), KE]

            global_i += 1

        try:
            configs[highest_E_i] = atom_readers[highest_E_i].next()
            energies[highest_E_i] = configs[highest_E_i].info['ns_energy']
            # print "incremented energies for stream ",highest_E_i,"to",energies[highest_E_i]
        except:
            # print "stream ",highest_E_i,"out of entries"
            n_done += 1
            configs[highest_E_i] = None
            energies[highest_E_i] = float('-inf')


if not opt.trajectory:
   print "# i     H      V        KE"

if not opt.trajectory and not opt.no_headers:
    data=[]
    for file in args:
        data.extend(process_headers(file))
    data.sort(key = lambda d: -d[1])
    for d in data[0::opt.interval]:
        print d[0], d[1], d[2], d[3]
else:
   outfile=quippy.AtomsWriter(opt.output, format=opt.format)
   for d in traj_iter(args, opt.interval, opt.energies_file):
      if opt.trajectory:
         outfile.write(d)
      else:
         print d[0], d[1], d[2], d[3]
   outfile.close()
